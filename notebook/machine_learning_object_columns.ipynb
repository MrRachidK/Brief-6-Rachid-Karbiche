{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('env')",
   "metadata": {
    "interpreter": {
     "hash": "6a174cddc737e4f490722fa7bff7ce010d24fcb0e55a51702f19518320f3b9a0"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Importation des données et configuration du data set"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 926,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We import all the libraries we'll need for the exercise\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# We load the CSV file we need to study\n",
    "housing_object_studying = pd.read_csv('/home/apprenant/Documents/Brief-6-Rachid-Karbiche/data/02_intermediate_data/cleaned_all_housing_data.csv')"
   ]
  },
  {
   "source": [
    "## Exploration des données"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 927,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Id', 'MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea',\n",
       "       'Street', 'LotShape', 'LandContour', 'Utilities', 'LotConfig',\n",
       "       'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType',\n",
       "       'HouseStyle', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd',\n",
       "       'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType',\n",
       "       'MasVnrArea', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual',\n",
       "       'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1',\n",
       "       'BsmtFinType2', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating',\n",
       "       'HeatingQC', 'CentralAir', 'Electrical', '1stFlrSF', '2ndFlrSF',\n",
       "       'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath',\n",
       "       'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual',\n",
       "       'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'GarageType', 'GarageYrBlt',\n",
       "       'GarageFinish', 'GarageCars', 'GarageArea', 'GarageQual', 'GarageCond',\n",
       "       'PavedDrive', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch',\n",
       "       'ScreenPorch', 'PoolArea', 'MiscVal', 'MoSold', 'YrSold', 'SaleType',\n",
       "       'SaleCondition', 'SalePrice'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 927
    }
   ],
   "source": [
    "housing_object_studying.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 928,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      Unnamed: 0    Id  MSSubClass MSZoning  LotFrontage  LotArea Street  \\\n",
       "0              0     1          60       RL         65.0     8450   Pave   \n",
       "1              1     2          20       RL         80.0     9600   Pave   \n",
       "2              2     3          60       RL         68.0    11250   Pave   \n",
       "3              3     4          70       RL         60.0     9550   Pave   \n",
       "4              4     5          60       RL         84.0    14260   Pave   \n",
       "...          ...   ...         ...      ...          ...      ...    ...   \n",
       "1455        1455  1456          60       RL         62.0     7917   Pave   \n",
       "1456        1456  1457          20       RL         85.0    13175   Pave   \n",
       "1457        1457  1458          70       RL         66.0     9042   Pave   \n",
       "1458        1458  1459          20       RL         68.0     9717   Pave   \n",
       "1459        1459  1460          20       RL         75.0     9937   Pave   \n",
       "\n",
       "     LotShape LandContour Utilities  ... EnclosedPorch 3SsnPorch ScreenPorch  \\\n",
       "0         Reg         Lvl    AllPub  ...             0         0           0   \n",
       "1         Reg         Lvl    AllPub  ...             0         0           0   \n",
       "2         IR1         Lvl    AllPub  ...             0         0           0   \n",
       "3         IR1         Lvl    AllPub  ...           272         0           0   \n",
       "4         IR1         Lvl    AllPub  ...             0         0           0   \n",
       "...       ...         ...       ...  ...           ...       ...         ...   \n",
       "1455      Reg         Lvl    AllPub  ...             0         0           0   \n",
       "1456      Reg         Lvl    AllPub  ...             0         0           0   \n",
       "1457      Reg         Lvl    AllPub  ...             0         0           0   \n",
       "1458      Reg         Lvl    AllPub  ...           112         0           0   \n",
       "1459      Reg         Lvl    AllPub  ...             0         0           0   \n",
       "\n",
       "     PoolArea MiscVal MoSold YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0           0       0      2   2008        WD         Normal     208500  \n",
       "1           0       0      5   2007        WD         Normal     181500  \n",
       "2           0       0      9   2008        WD         Normal     223500  \n",
       "3           0       0      2   2006        WD        Abnorml     140000  \n",
       "4           0       0     12   2008        WD         Normal     250000  \n",
       "...       ...     ...    ...    ...       ...            ...        ...  \n",
       "1455        0       0      8   2007        WD         Normal     175000  \n",
       "1456        0       0      2   2010        WD         Normal     210000  \n",
       "1457        0    2500      5   2010        WD         Normal     266500  \n",
       "1458        0       0      4   2010        WD         Normal     142125  \n",
       "1459        0       0      6   2008        WD         Normal     147500  \n",
       "\n",
       "[1460 rows x 77 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>Id</th>\n      <th>MSSubClass</th>\n      <th>MSZoning</th>\n      <th>LotFrontage</th>\n      <th>LotArea</th>\n      <th>Street</th>\n      <th>LotShape</th>\n      <th>LandContour</th>\n      <th>Utilities</th>\n      <th>...</th>\n      <th>EnclosedPorch</th>\n      <th>3SsnPorch</th>\n      <th>ScreenPorch</th>\n      <th>PoolArea</th>\n      <th>MiscVal</th>\n      <th>MoSold</th>\n      <th>YrSold</th>\n      <th>SaleType</th>\n      <th>SaleCondition</th>\n      <th>SalePrice</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1</td>\n      <td>60</td>\n      <td>RL</td>\n      <td>65.0</td>\n      <td>8450</td>\n      <td>Pave</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2008</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>208500</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2</td>\n      <td>20</td>\n      <td>RL</td>\n      <td>80.0</td>\n      <td>9600</td>\n      <td>Pave</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>2007</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>181500</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>3</td>\n      <td>60</td>\n      <td>RL</td>\n      <td>68.0</td>\n      <td>11250</td>\n      <td>Pave</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>9</td>\n      <td>2008</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>223500</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>4</td>\n      <td>70</td>\n      <td>RL</td>\n      <td>60.0</td>\n      <td>9550</td>\n      <td>Pave</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>272</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2006</td>\n      <td>WD</td>\n      <td>Abnorml</td>\n      <td>140000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>5</td>\n      <td>60</td>\n      <td>RL</td>\n      <td>84.0</td>\n      <td>14260</td>\n      <td>Pave</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>12</td>\n      <td>2008</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>250000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1455</th>\n      <td>1455</td>\n      <td>1456</td>\n      <td>60</td>\n      <td>RL</td>\n      <td>62.0</td>\n      <td>7917</td>\n      <td>Pave</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8</td>\n      <td>2007</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>175000</td>\n    </tr>\n    <tr>\n      <th>1456</th>\n      <td>1456</td>\n      <td>1457</td>\n      <td>20</td>\n      <td>RL</td>\n      <td>85.0</td>\n      <td>13175</td>\n      <td>Pave</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2010</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>210000</td>\n    </tr>\n    <tr>\n      <th>1457</th>\n      <td>1457</td>\n      <td>1458</td>\n      <td>70</td>\n      <td>RL</td>\n      <td>66.0</td>\n      <td>9042</td>\n      <td>Pave</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2500</td>\n      <td>5</td>\n      <td>2010</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>266500</td>\n    </tr>\n    <tr>\n      <th>1458</th>\n      <td>1458</td>\n      <td>1459</td>\n      <td>20</td>\n      <td>RL</td>\n      <td>68.0</td>\n      <td>9717</td>\n      <td>Pave</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>112</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>2010</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>142125</td>\n    </tr>\n    <tr>\n      <th>1459</th>\n      <td>1459</td>\n      <td>1460</td>\n      <td>20</td>\n      <td>RL</td>\n      <td>75.0</td>\n      <td>9937</td>\n      <td>Pave</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6</td>\n      <td>2008</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>147500</td>\n    </tr>\n  </tbody>\n</table>\n<p>1460 rows × 77 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 928
    }
   ],
   "source": [
    "housing_object_studying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 929,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
       "0             60         65.0     8450            7            5       2003   \n",
       "1             20         80.0     9600            6            8       1976   \n",
       "2             60         68.0    11250            7            5       2001   \n",
       "3             70         60.0     9550            7            5       1915   \n",
       "4             60         84.0    14260            8            5       2000   \n",
       "...          ...          ...      ...          ...          ...        ...   \n",
       "1455          60         62.0     7917            6            5       1999   \n",
       "1456          20         85.0    13175            6            6       1978   \n",
       "1457          70         66.0     9042            7            9       1941   \n",
       "1458          20         68.0     9717            5            6       1950   \n",
       "1459          20         75.0     9937            5            6       1965   \n",
       "\n",
       "      YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2  ...  GarageArea  \\\n",
       "0             2003       196.0         706           0  ...         548   \n",
       "1             1976         0.0         978           0  ...         460   \n",
       "2             2002       162.0         486           0  ...         608   \n",
       "3             1970         0.0         216           0  ...         642   \n",
       "4             2000       350.0         655           0  ...         836   \n",
       "...            ...         ...         ...         ...  ...         ...   \n",
       "1455          2000         0.0           0           0  ...         460   \n",
       "1456          1988       119.0         790         163  ...         500   \n",
       "1457          2006         0.0         275           0  ...         252   \n",
       "1458          1996         0.0          49        1029  ...         240   \n",
       "1459          1965         0.0         830         290  ...         276   \n",
       "\n",
       "      WoodDeckSF  OpenPorchSF  EnclosedPorch  3SsnPorch  ScreenPorch  \\\n",
       "0              0           61              0          0            0   \n",
       "1            298            0              0          0            0   \n",
       "2              0           42              0          0            0   \n",
       "3              0           35            272          0            0   \n",
       "4            192           84              0          0            0   \n",
       "...          ...          ...            ...        ...          ...   \n",
       "1455           0           40              0          0            0   \n",
       "1456         349            0              0          0            0   \n",
       "1457           0           60              0          0            0   \n",
       "1458         366            0            112          0            0   \n",
       "1459         736           68              0          0            0   \n",
       "\n",
       "      PoolArea  MiscVal  MoSold  YrSold  \n",
       "0            0        0       2    2008  \n",
       "1            0        0       5    2007  \n",
       "2            0        0       9    2008  \n",
       "3            0        0       2    2006  \n",
       "4            0        0      12    2008  \n",
       "...        ...      ...     ...     ...  \n",
       "1455         0        0       8    2007  \n",
       "1456         0        0       2    2010  \n",
       "1457         0     2500       5    2010  \n",
       "1458         0        0       4    2010  \n",
       "1459         0        0       6    2008  \n",
       "\n",
       "[1460 rows x 36 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MSSubClass</th>\n      <th>LotFrontage</th>\n      <th>LotArea</th>\n      <th>OverallQual</th>\n      <th>OverallCond</th>\n      <th>YearBuilt</th>\n      <th>YearRemodAdd</th>\n      <th>MasVnrArea</th>\n      <th>BsmtFinSF1</th>\n      <th>BsmtFinSF2</th>\n      <th>...</th>\n      <th>GarageArea</th>\n      <th>WoodDeckSF</th>\n      <th>OpenPorchSF</th>\n      <th>EnclosedPorch</th>\n      <th>3SsnPorch</th>\n      <th>ScreenPorch</th>\n      <th>PoolArea</th>\n      <th>MiscVal</th>\n      <th>MoSold</th>\n      <th>YrSold</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>60</td>\n      <td>65.0</td>\n      <td>8450</td>\n      <td>7</td>\n      <td>5</td>\n      <td>2003</td>\n      <td>2003</td>\n      <td>196.0</td>\n      <td>706</td>\n      <td>0</td>\n      <td>...</td>\n      <td>548</td>\n      <td>0</td>\n      <td>61</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2008</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20</td>\n      <td>80.0</td>\n      <td>9600</td>\n      <td>6</td>\n      <td>8</td>\n      <td>1976</td>\n      <td>1976</td>\n      <td>0.0</td>\n      <td>978</td>\n      <td>0</td>\n      <td>...</td>\n      <td>460</td>\n      <td>298</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>2007</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>60</td>\n      <td>68.0</td>\n      <td>11250</td>\n      <td>7</td>\n      <td>5</td>\n      <td>2001</td>\n      <td>2002</td>\n      <td>162.0</td>\n      <td>486</td>\n      <td>0</td>\n      <td>...</td>\n      <td>608</td>\n      <td>0</td>\n      <td>42</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>9</td>\n      <td>2008</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>70</td>\n      <td>60.0</td>\n      <td>9550</td>\n      <td>7</td>\n      <td>5</td>\n      <td>1915</td>\n      <td>1970</td>\n      <td>0.0</td>\n      <td>216</td>\n      <td>0</td>\n      <td>...</td>\n      <td>642</td>\n      <td>0</td>\n      <td>35</td>\n      <td>272</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2006</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>60</td>\n      <td>84.0</td>\n      <td>14260</td>\n      <td>8</td>\n      <td>5</td>\n      <td>2000</td>\n      <td>2000</td>\n      <td>350.0</td>\n      <td>655</td>\n      <td>0</td>\n      <td>...</td>\n      <td>836</td>\n      <td>192</td>\n      <td>84</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>12</td>\n      <td>2008</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1455</th>\n      <td>60</td>\n      <td>62.0</td>\n      <td>7917</td>\n      <td>6</td>\n      <td>5</td>\n      <td>1999</td>\n      <td>2000</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>460</td>\n      <td>0</td>\n      <td>40</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8</td>\n      <td>2007</td>\n    </tr>\n    <tr>\n      <th>1456</th>\n      <td>20</td>\n      <td>85.0</td>\n      <td>13175</td>\n      <td>6</td>\n      <td>6</td>\n      <td>1978</td>\n      <td>1988</td>\n      <td>119.0</td>\n      <td>790</td>\n      <td>163</td>\n      <td>...</td>\n      <td>500</td>\n      <td>349</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2010</td>\n    </tr>\n    <tr>\n      <th>1457</th>\n      <td>70</td>\n      <td>66.0</td>\n      <td>9042</td>\n      <td>7</td>\n      <td>9</td>\n      <td>1941</td>\n      <td>2006</td>\n      <td>0.0</td>\n      <td>275</td>\n      <td>0</td>\n      <td>...</td>\n      <td>252</td>\n      <td>0</td>\n      <td>60</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2500</td>\n      <td>5</td>\n      <td>2010</td>\n    </tr>\n    <tr>\n      <th>1458</th>\n      <td>20</td>\n      <td>68.0</td>\n      <td>9717</td>\n      <td>5</td>\n      <td>6</td>\n      <td>1950</td>\n      <td>1996</td>\n      <td>0.0</td>\n      <td>49</td>\n      <td>1029</td>\n      <td>...</td>\n      <td>240</td>\n      <td>366</td>\n      <td>0</td>\n      <td>112</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>2010</td>\n    </tr>\n    <tr>\n      <th>1459</th>\n      <td>20</td>\n      <td>75.0</td>\n      <td>9937</td>\n      <td>5</td>\n      <td>6</td>\n      <td>1965</td>\n      <td>1965</td>\n      <td>0.0</td>\n      <td>830</td>\n      <td>290</td>\n      <td>...</td>\n      <td>276</td>\n      <td>736</td>\n      <td>68</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6</td>\n      <td>2008</td>\n    </tr>\n  </tbody>\n</table>\n<p>1460 rows × 36 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 929
    }
   ],
   "source": [
    "numerical_columns = housing_object_studying[housing_object_studying.select_dtypes([int, float]).columns.to_list()]\n",
    "sale_column = numerical_columns['SalePrice']\n",
    "numerical_columns = numerical_columns.drop(columns=['Unnamed: 0', 'Id', 'SalePrice'])\n",
    "numerical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 930,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0       208500\n",
       "1       181500\n",
       "2       223500\n",
       "3       140000\n",
       "4       250000\n",
       "         ...  \n",
       "1455    175000\n",
       "1456    210000\n",
       "1457    266500\n",
       "1458    142125\n",
       "1459    147500\n",
       "Name: SalePrice, Length: 1460, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 930
    }
   ],
   "source": [
    "sale_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 931,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = pd.get_dummies(housing_object_studying[housing_object_studying.select_dtypes(object).columns.to_list()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 932,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
       "0             60         65.0     8450            7            5       2003   \n",
       "1             20         80.0     9600            6            8       1976   \n",
       "2             60         68.0    11250            7            5       2001   \n",
       "3             70         60.0     9550            7            5       1915   \n",
       "4             60         84.0    14260            8            5       2000   \n",
       "...          ...          ...      ...          ...          ...        ...   \n",
       "1455          60         62.0     7917            6            5       1999   \n",
       "1456          20         85.0    13175            6            6       1978   \n",
       "1457          70         66.0     9042            7            9       1941   \n",
       "1458          20         68.0     9717            5            6       1950   \n",
       "1459          20         75.0     9937            5            6       1965   \n",
       "\n",
       "      YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2  ...  SaleType_ConLw  \\\n",
       "0             2003       196.0         706           0  ...               0   \n",
       "1             1976         0.0         978           0  ...               0   \n",
       "2             2002       162.0         486           0  ...               0   \n",
       "3             1970         0.0         216           0  ...               0   \n",
       "4             2000       350.0         655           0  ...               0   \n",
       "...            ...         ...         ...         ...  ...             ...   \n",
       "1455          2000         0.0           0           0  ...               0   \n",
       "1456          1988       119.0         790         163  ...               0   \n",
       "1457          2006         0.0         275           0  ...               0   \n",
       "1458          1996         0.0          49        1029  ...               0   \n",
       "1459          1965         0.0         830         290  ...               0   \n",
       "\n",
       "      SaleType_New  SaleType_Oth  SaleType_WD  SaleCondition_Abnorml  \\\n",
       "0                0             0            1                      0   \n",
       "1                0             0            1                      0   \n",
       "2                0             0            1                      0   \n",
       "3                0             0            1                      1   \n",
       "4                0             0            1                      0   \n",
       "...            ...           ...          ...                    ...   \n",
       "1455             0             0            1                      0   \n",
       "1456             0             0            1                      0   \n",
       "1457             0             0            1                      0   \n",
       "1458             0             0            1                      0   \n",
       "1459             0             0            1                      0   \n",
       "\n",
       "      SaleCondition_AdjLand  SaleCondition_Alloca  SaleCondition_Family  \\\n",
       "0                         0                     0                     0   \n",
       "1                         0                     0                     0   \n",
       "2                         0                     0                     0   \n",
       "3                         0                     0                     0   \n",
       "4                         0                     0                     0   \n",
       "...                     ...                   ...                   ...   \n",
       "1455                      0                     0                     0   \n",
       "1456                      0                     0                     0   \n",
       "1457                      0                     0                     0   \n",
       "1458                      0                     0                     0   \n",
       "1459                      0                     0                     0   \n",
       "\n",
       "      SaleCondition_Normal  SaleCondition_Partial  \n",
       "0                        1                      0  \n",
       "1                        1                      0  \n",
       "2                        1                      0  \n",
       "3                        0                      0  \n",
       "4                        1                      0  \n",
       "...                    ...                    ...  \n",
       "1455                     1                      0  \n",
       "1456                     1                      0  \n",
       "1457                     1                      0  \n",
       "1458                     1                      0  \n",
       "1459                     1                      0  \n",
       "\n",
       "[1460 rows x 270 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MSSubClass</th>\n      <th>LotFrontage</th>\n      <th>LotArea</th>\n      <th>OverallQual</th>\n      <th>OverallCond</th>\n      <th>YearBuilt</th>\n      <th>YearRemodAdd</th>\n      <th>MasVnrArea</th>\n      <th>BsmtFinSF1</th>\n      <th>BsmtFinSF2</th>\n      <th>...</th>\n      <th>SaleType_ConLw</th>\n      <th>SaleType_New</th>\n      <th>SaleType_Oth</th>\n      <th>SaleType_WD</th>\n      <th>SaleCondition_Abnorml</th>\n      <th>SaleCondition_AdjLand</th>\n      <th>SaleCondition_Alloca</th>\n      <th>SaleCondition_Family</th>\n      <th>SaleCondition_Normal</th>\n      <th>SaleCondition_Partial</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>60</td>\n      <td>65.0</td>\n      <td>8450</td>\n      <td>7</td>\n      <td>5</td>\n      <td>2003</td>\n      <td>2003</td>\n      <td>196.0</td>\n      <td>706</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20</td>\n      <td>80.0</td>\n      <td>9600</td>\n      <td>6</td>\n      <td>8</td>\n      <td>1976</td>\n      <td>1976</td>\n      <td>0.0</td>\n      <td>978</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>60</td>\n      <td>68.0</td>\n      <td>11250</td>\n      <td>7</td>\n      <td>5</td>\n      <td>2001</td>\n      <td>2002</td>\n      <td>162.0</td>\n      <td>486</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>70</td>\n      <td>60.0</td>\n      <td>9550</td>\n      <td>7</td>\n      <td>5</td>\n      <td>1915</td>\n      <td>1970</td>\n      <td>0.0</td>\n      <td>216</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>60</td>\n      <td>84.0</td>\n      <td>14260</td>\n      <td>8</td>\n      <td>5</td>\n      <td>2000</td>\n      <td>2000</td>\n      <td>350.0</td>\n      <td>655</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1455</th>\n      <td>60</td>\n      <td>62.0</td>\n      <td>7917</td>\n      <td>6</td>\n      <td>5</td>\n      <td>1999</td>\n      <td>2000</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1456</th>\n      <td>20</td>\n      <td>85.0</td>\n      <td>13175</td>\n      <td>6</td>\n      <td>6</td>\n      <td>1978</td>\n      <td>1988</td>\n      <td>119.0</td>\n      <td>790</td>\n      <td>163</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1457</th>\n      <td>70</td>\n      <td>66.0</td>\n      <td>9042</td>\n      <td>7</td>\n      <td>9</td>\n      <td>1941</td>\n      <td>2006</td>\n      <td>0.0</td>\n      <td>275</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1458</th>\n      <td>20</td>\n      <td>68.0</td>\n      <td>9717</td>\n      <td>5</td>\n      <td>6</td>\n      <td>1950</td>\n      <td>1996</td>\n      <td>0.0</td>\n      <td>49</td>\n      <td>1029</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1459</th>\n      <td>20</td>\n      <td>75.0</td>\n      <td>9937</td>\n      <td>5</td>\n      <td>6</td>\n      <td>1965</td>\n      <td>1965</td>\n      <td>0.0</td>\n      <td>830</td>\n      <td>290</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1460 rows × 270 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 932
    }
   ],
   "source": [
    "concatenated_columns = pd.concat([numerical_columns, categorical_columns], axis=1)\n",
    "concatenated_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 933,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "MSSubClass                 0\n",
       "ExterCond_Gd               0\n",
       "ExterCond_Po               0\n",
       "ExterCond_TA               0\n",
       "Foundation_BrkTil          0\n",
       "                        ... \n",
       "Condition1_RRAn            0\n",
       "SaleCondition_Partial      0\n",
       "MasVnrArea                 8\n",
       "GarageYrBlt               81\n",
       "LotFrontage              259\n",
       "Length: 270, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 933
    }
   ],
   "source": [
    "concatenated_columns.isna().sum().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 934,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_columns = concatenated_columns.drop(columns=['MasVnrArea', 'GarageYrBlt', 'LotFrontage'])"
   ]
  },
  {
   "source": [
    "## Préparation des données"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Sélection de la variable cible et des variables explicatives"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 935,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "source": [
    "On définit à présent notre variable cible"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Ainsi que nos variables explicatives"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 936,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelizing_linear_regression(database, target_value, evaluated_values):\n",
    "    y = target_value\n",
    "    x = database[evaluated_values]\n",
    "    xtrain, xtest, ytrain, ytest = train_test_split(x, y, train_size=0.8)\n",
    "    regr = linear_model.LinearRegression()\n",
    "    regr.fit(xtrain, ytrain)\n",
    "    return regr, xtrain, ytrain, xtest, ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 937,
   "metadata": {},
   "outputs": [],
   "source": [
    "defined_regr, x_train, y_train, x_test, y_test = modelizing_linear_regression(concatenated_columns, sale_column, concatenated_columns.columns.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 938,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "22.93521101852475\n0.9574731748593619\n6421.3701700542115\n5913.240154408849\n338.2728415618498\n83.18464050656581\n16.57702109136096\n10.09281873886448\n-1.9889828840936161\n24.68136560803714\n13.885345803829068\n42.95677050461313\n-25.34507044623024\n31.497001512401766\n-72.05202552859282\n924.4341314884932\n3461.227009154992\n606.2979149522166\n-3040.5650857749397\n-15855.785518738992\n921.5837638833164\n2536.9664555932777\n4096.546394353304\n20.63800815523973\n12.795001368349403\n-5.44072745059475\n3.4143097881060385\n18.603888064624698\n33.329258971335776\n77.3183768267836\n-0.6195859683284652\n-446.1071850296212\n-265.74423690127696\n-25953.621643374267\n17933.43948873761\n2477.6923019024107\n4207.179468271548\n1335.3103847579741\n-14529.813346392159\n14529.813346174738\n-2185.64603118752\n-1388.0755442515324\n4022.6126668366296\n-448.8910893629361\n314.3290160260658\n8815.67549259046\n-18448.5777167678\n9318.573207976688\n14233.369877521023\n-14233.36987756814\n4179.232753836518\n13789.061950182633\n-4772.283798752213\n-15746.78341626923\n2550.7725097904504\n19580.689344521248\n27329.86312352374\n-46910.552468179914\n-2421.8804791869766\n7378.834991383797\n7166.421195562127\n-633.2202438289789\n-11605.234517262845\n-9264.252852484806\n14272.623633516729\n-18363.446353845007\n-6722.298686695067\n-4564.979969720168\n-5276.709967095891\n-21587.236787865506\n-14323.839047451396\n16068.410599140081\n-17496.57516882706\n30807.74858456987\n18115.535995596776\n-10816.854494512327\n2331.7638304411803\n-9094.773981428434\n-1757.608910146786\n-3396.2873051580436\n45327.71720870858\n-10081.690151388077\n5937.83287838472\n-4347.825714196728\n3534.6308862035107\n11750.287937332769\n3291.547504735141\n13811.374803923543\n-24483.434713962415\n1433.1421699356858\n-8070.382729025931\n3080.65985453792\n71958.62466081366\n61766.58364989486\n51863.735426286396\n-4.31100488640368e-10\n-185086.4168757789\n-95671.87664593513\n35720.44280153851\n59448.90698323636\n14219.538880170492\n1394.3344332173983\n7298.936106430658\n-13677.839834398612\n-9234.96958186822\n2030.8561157172744\n16381.127178376883\n14480.28556079062\n-31026.006126427856\n-9856.452419015955\n-6092.643122586007\n8817.364513347338\n5265.468299430834\n-28744.77256785167\n-20710.151407579848\n-19129.34862231739\n-19846.870445758108\n-8824.773505134595\n97255.91654853025\n-623494.7908223644\n47903.58348641276\n183412.46815048112\n152678.8135705443\n37404.60391935552\n59562.133262087686\n41701.12352180829\n100832.06491163428\n22940.59016558562\n-18459.75011550925\n-1805.1225027028797\n21947.92909862245\n-8200.477849880002\n2404.2050769888274\n-4106.012289301259\n-40353.57381882787\n11273.198129402663\n-8474.016151573309\n15164.214446625863\n9995.509602720735\n-1325.759552271732\n-1885.0742212038049\n884.139981335549\n-17574.958239016167\n5500.103585515901\n9275.330502387485\n-2357.244385261128\n-8200.477849894085\n9597.437184147551\n7709.87090457813\n24601.07772680715\n-4769.13621057984\n-27260.350928494783\n8104.0341465889505\n-19906.900762142042\n-3369.7502571908026\n7901.963845578948\n7227.0459953690215\n3521.954744311679\n8591.227277658621\n14955.114830344854\n13632.47965565182\n21186.13615725603\n11618.709557616017\n11166.88413198329\n-10948.825971886034\n-11836.767717800005\n-4269.738344796161\n-677.0756598884673\n-5575.454094025108\n13553.76734953267\n-3031.499250670753\n1525.3663611177917\n4294.307874590629\n6884.908259657989\n-14674.908261442133\n10765.339435584285\n-8795.01366958807\n-1421.722143945186\n-12367.862976553912\n-20556.7307715542\n-16825.397671900086\n-35669.66314029234\n-39898.629518694295\n58571.67661706033\n-34175.09752239273\n14064.676954410696\n27022.02964318965\n7517.349106594982\n6430.641283670989\n-10804.892518494686\n-6177.442670270938\n-4360.774798386263\n-13839.239741970954\n-7921.3266691609\n-8068.037165793792\n29446.099916543673\n18584.04184868577\n25197.519173962548\n15714.25915114498\n22710.692548059582\n22577.578062504872\n-16048.343693960293\n6006.77627618421\n470.7415306122625\n2224.16725596652\n-19437.541750804532\n26784.200381874743\n-1424.5491234577003\n1381.67684767327\n-3627.0231380727337\n7256.435810833935\n-3586.5403967212005\n-179.02649142940822\n179.02649185396376\n-18051.00181813769\n-20032.605234675906\n-78188.29224748546\n-152220.4721598496\n-19655.513701770913\n17161.597534011747\n-2502.8604677067874\n-8216.635352444344\n-6442.1017138193865\n-1155.042201064593\n9685.42871157419\n9973.777945773318\n8371.50461586932\n-8875.042456422354\n-39173.72238874853\n21173.095772909895\n-21168.617191156227\n1549.3245955782777\n9474.798847268603\n-2007.878921812453\n-1048.2185210258936\n4584.798897441881\n-2991.1191467214803\n-3953.375220676482\n-1671.2979274516383\n90531.67115561124\n-34352.63276283503\n-33139.1824741638\n-2499.2622732677787\n-29156.385939588607\n-95994.37967541422\n21585.029626639338\n18803.79628415113\n25946.112740805533\n21043.648729269207\n1752.2477780943186\n-2101.7097518851733\n349.46197348122087\n-9547.088063699965\n4960.871866776852\n15791.66942056061\n9462.91116429249\n-3650.6786800898217\n-12431.89170606338\n4047.9666112679724\n738.5211850176967\n-9372.281798072792\n-9504.775469498622\n19546.285521024205\n2345.167875457858\n-7988.212628120975\n-3085.2745596192963\n-1313.19073915653\n"
     ]
    }
   ],
   "source": [
    "for i in defined_regr.coef_:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 939,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = concatenated_housing_data['SalePrice']\n",
    "# x = concatenated_housing_data[['GrLivArea']]\n",
    "# xtrain, xtest, ytrain, ytest = train_test_split(x, y, train_size=0.8)\n",
    "# regr = linear_model.LinearRegression()\n",
    "# regr.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 940,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Les coefficients β1 sont égaux à {}, {}, {} et {} tandis que l'intercept β0 est égal à {}\"\n",
    "#       .format(round(defined_regr.coef_[0],2), round(defined_regr.coef_[1],2), round(defined_regr.coef_[2],2), round(defined_regr.coef_[3],2), round(defined_regr.intercept_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 941,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_y_variable(predicted_values, evaluated_values):\n",
    "    dataframe = pd.DataFrame({})\n",
    "    for i in range(len(predicted_values)):\n",
    "        dataframe[evaluated_values[i]] = [predicted_values[i]]\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 942,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluated_dataframe = predict_y_variable([0, 0, 0, 1], ['MSZoning_FV','MSZoning_RH','MSZoning_RL','MSZoning_RM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 943,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_prediction(regression_value, dataframe):\n",
    "    print(\"Selon le modèle étudié, nous obtenons la valeur suivante : {}\"\n",
    "      .format(round(regression_value.predict(dataframe)[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 944,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_prediction(defined_regr, evaluated_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 945,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain_pred = defined_regr.predict(x_train)\n",
    "ytest_pred = defined_regr.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 946,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_metrics(model, x, y, b1=True, b0=True, title=None):\n",
    "    \"\"\"\n",
    "        Separate data in train and test sets,\n",
    "        fit the model,\n",
    "        make predictions on train and test datas,\n",
    "        print metrics\n",
    "\n",
    "        params:\n",
    "            model(function): model used with params (ie: Lasso(alpha=x)) \n",
    "            X(DataFrame): DataFrame subset with selected features,\n",
    "            y(Series): variable to predict\n",
    "\n",
    "        returns: \n",
    "                print β1, β0, R2 and RMSE\n",
    "    \"\"\"\n",
    "    # Split des datas\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "        x, y, train_size=0.8, random_state=1\n",
    "    )\n",
    "    model.fit(x_train, y_train)\n",
    "    if title:\n",
    "        print(f\"{title} : \")\n",
    "    if b1:\n",
    "        # Affichage des β1 pour chaque variable\n",
    "        for idx, name in enumerate(X_train.columns):\n",
    "            print(f\"β1 de {name} : {round(model.coef_[idx], 3)}\")\n",
    "    if b0:\n",
    "        print(f\"β0 (intercept_) : {round(model.intercept_, 3)}\\n\")\n",
    "\n",
    "    y_train_pred = model.predict(x_train)\n",
    "    y_test_pred = model.predict(x_test)\n",
    "\n",
    "    y_list = [y_train, y_train_pred, y_test, y_test_pred]\n",
    "    get_r2_rmse(y_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 947,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_r2_rmse(y_list):\n",
    "    \"\"\"\n",
    "        calculate R2 and RMSE for each sets (train and test)\n",
    "        and format output\n",
    "\n",
    "        param:\n",
    "            y_list = [\n",
    "                y_train, \n",
    "                y_train_pred, \n",
    "                y_test, \n",
    "                y_test_pred\n",
    "            ]\n",
    "    \"\"\"\n",
    "\n",
    "    sets = [\"Training\", \"Testing \"]\n",
    "    i = 0\n",
    "    for set in sets:\n",
    "        r2 = round(r2_score(y_list[i], y_list[i+1]), 3)\n",
    "        rmse = round(mean_squared_error(\n",
    "            y_list[i], y_list[i+1], squared=False), 3)\n",
    "        print(\n",
    "            \"{} set : R2 = {}, RMSE = {}\".format(set, r2, rmse)\n",
    "        )\n",
    "        i += 2\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 948,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Pour les données d'entrainement le R2 vaut 0.928 alors que pour les données de test, il est de 0.91\n"
     ]
    }
   ],
   "source": [
    "print (\"Pour les données d'entrainement le R2 vaut {} alors que pour les données de test, il est de {}\" \n",
    "      .format(round(r2_score(y_train, ytrain_pred),3), round(r2_score(y_test, ytest_pred),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 949,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Pour les données d'entrainement le RMSE vaut 21851.693 alors que pour les données de test, il est de 20991.311\n"
     ]
    }
   ],
   "source": [
    "print (\"Pour les données d'entrainement le RMSE vaut {} alors que pour les données de test, il est de {}\" \n",
    "      .format(round(mean_squared_error(y_train, ytrain_pred, squared=False),3), \n",
    "              round(mean_squared_error(y_test, ytest_pred, squared=False),3)))"
   ]
  },
  {
   "source": [
    "## Régression Ridge"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 950,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelizing_ridge_regression(database, target_value, evaluated_values, determined_alpha, normalize=False):\n",
    "    y = target_value\n",
    "    x = database[evaluated_values]\n",
    "    xtrain, xtest, ytrain, ytest = train_test_split(x, y, train_size=0.8)\n",
    "    regr = linear_model.Ridge(alpha=determined_alpha, normalize=True)\n",
    "    regr.fit(xtrain, ytrain)\n",
    "    return regr, xtrain, ytrain, xtest, ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 951,
   "metadata": {},
   "outputs": [],
   "source": [
    "defined_ridge_regr, x_train_ridge, y_train_ridge, x_test_ridge, y_test_ridge = modelizing_ridge_regression(concatenated_columns, sale_column, concatenated_columns.columns.to_list(), 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 952,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain_pred_ridge = defined_ridge_regr.predict(x_train_ridge)\n",
    "ytest_pred_ridge = defined_ridge_regr.predict(x_test_ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 953,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Pour les données d'entrainement le R2 vaut 0.717 alors que pour les données de test, il est de 0.755\n"
     ]
    }
   ],
   "source": [
    "print (\"Pour les données d'entrainement le R2 vaut {} alors que pour les données de test, il est de {}\" \n",
    "      .format(round(r2_score(y_train_ridge, ytrain_pred_ridge),3), round(r2_score(y_test_ridge, ytest_pred_ridge),3)))"
   ]
  },
  {
   "source": [
    "## Régression Lasso"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 954,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelizing_lasso_regression(database, target_value, evaluated_values, determined_alpha):\n",
    "    y = target_value\n",
    "    x = database[evaluated_values]\n",
    "    xtrain, xtest, ytrain, ytest = train_test_split(x, y, train_size=0.8)\n",
    "    regr = linear_model.Lasso(alpha=determined_alpha)\n",
    "    regr.fit(xtrain, ytrain)\n",
    "    return regr, xtrain, ytrain, xtest, ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 955,
   "metadata": {},
   "outputs": [],
   "source": [
    "defined_lasso_regr, x_train_lasso, y_train_lasso, x_test_lasso, y_test_lasso = modelizing_lasso_regression(concatenated_columns, sale_column, concatenated_columns.columns.to_list(), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 956,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain_pred_lasso = defined_lasso_regr.predict(x_train_lasso)\n",
    "ytest_pred_lasso = defined_lasso_regr.predict(x_test_lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 957,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Pour les données d'entrainement le R2 vaut 0.934 alors que pour les données de test, il est de 0.889\n"
     ]
    }
   ],
   "source": [
    "print (\"Pour les données d'entrainement le R2 vaut {} alors que pour les données de test, il est de {}\" \n",
    "      .format(round(r2_score(y_train_lasso, ytrain_pred_lasso),3), round(r2_score(y_test_lasso, ytest_pred_lasso),3)))"
   ]
  },
  {
   "source": [
    "## Utilisation du GridSearchCV (Cross-Validation)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 958,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def modelizing_GridSearchCV(database, target_value, evaluated_values, defined_parameters, model_name):\n",
    "    y = target_value\n",
    "    x = database[evaluated_values]\n",
    "    parameters = defined_parameters\n",
    "    model = model_name\n",
    "    regr = GridSearchCV(model, parameters)\n",
    "    regr.fit(x, y)\n",
    "    return regr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 959,
   "metadata": {},
   "outputs": [],
   "source": [
    "defined_ridge_grid = modelizing_GridSearchCV(concatenated_columns, sale_column, concatenated_columns.columns.to_list(), {'alpha':np.arange(0, 10, 1).tolist(), 'normalize':[True,False]}, linear_model.Ridge())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 960,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_alpha  \\\n",
       "0        0.648920      0.259759         0.023654        0.006074           0   \n",
       "1        0.321581      0.102144         0.013781        0.007737           0   \n",
       "2        0.106468      0.045240         0.027765        0.012007           1   \n",
       "3        0.086091      0.021496         0.017611        0.004860           1   \n",
       "4        0.098017      0.034316         0.028329        0.011141           2   \n",
       "5        0.102939      0.027446         0.024647        0.005905           2   \n",
       "6        0.089519      0.024883         0.031928        0.009502           3   \n",
       "7        0.085205      0.026895         0.034763        0.011454           3   \n",
       "8        0.128895      0.029316         0.029292        0.004729           4   \n",
       "9        0.104173      0.015145         0.031349        0.007418           4   \n",
       "10       0.039652      0.006686         0.011052        0.004363           5   \n",
       "11       0.052750      0.018004         0.016676        0.009494           5   \n",
       "12       0.068757      0.028621         0.021318        0.017737           6   \n",
       "13       0.026467      0.008877         0.008103        0.004211           6   \n",
       "14       0.031730      0.011564         0.006957        0.002395           7   \n",
       "15       0.040627      0.014419         0.008409        0.004325           7   \n",
       "16       0.066196      0.035307         0.017093        0.005617           8   \n",
       "17       0.066799      0.014849         0.021475        0.008398           8   \n",
       "18       0.068988      0.023502         0.011926        0.004087           9   \n",
       "19       0.050481      0.025035         0.009082        0.005231           9   \n",
       "\n",
       "   param_normalize                            params  split0_test_score  \\\n",
       "0             True   {'alpha': 0, 'normalize': True}      -1.058609e+23   \n",
       "1            False  {'alpha': 0, 'normalize': False}      -2.039183e+18   \n",
       "2             True   {'alpha': 1, 'normalize': True}       9.065174e-01   \n",
       "3            False  {'alpha': 1, 'normalize': False}       9.026234e-01   \n",
       "4             True   {'alpha': 2, 'normalize': True}       8.816736e-01   \n",
       "5            False  {'alpha': 2, 'normalize': False}       9.042165e-01   \n",
       "6             True   {'alpha': 3, 'normalize': True}       8.560718e-01   \n",
       "7            False  {'alpha': 3, 'normalize': False}       9.044784e-01   \n",
       "8             True   {'alpha': 4, 'normalize': True}       8.311651e-01   \n",
       "9            False  {'alpha': 4, 'normalize': False}       9.046529e-01   \n",
       "10            True   {'alpha': 5, 'normalize': True}       8.072745e-01   \n",
       "11           False  {'alpha': 5, 'normalize': False}       9.048534e-01   \n",
       "12            True   {'alpha': 6, 'normalize': True}       7.844665e-01   \n",
       "13           False  {'alpha': 6, 'normalize': False}       9.050785e-01   \n",
       "14            True   {'alpha': 7, 'normalize': True}       7.627283e-01   \n",
       "15           False  {'alpha': 7, 'normalize': False}       9.053154e-01   \n",
       "16            True   {'alpha': 8, 'normalize': True}       7.420184e-01   \n",
       "17           False  {'alpha': 8, 'normalize': False}       9.055536e-01   \n",
       "18            True   {'alpha': 9, 'normalize': True}       7.222859e-01   \n",
       "19           False  {'alpha': 9, 'normalize': False}       9.057860e-01   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0       -3.968341e+23      -2.878326e+22      -1.776099e+22   \n",
       "1       -4.238480e+18      -1.051341e+18      -1.277339e+18   \n",
       "2        8.459223e-01       8.444678e-01       8.770281e-01   \n",
       "3        8.316129e-01       8.685269e-01       8.768996e-01   \n",
       "4        8.301339e-01       8.126712e-01       8.543397e-01   \n",
       "5        8.342819e-01       8.746565e-01       8.753836e-01   \n",
       "6        8.110771e-01       7.816641e-01       8.307184e-01   \n",
       "7        8.361798e-01       8.766061e-01       8.754993e-01   \n",
       "8        7.910181e-01       7.528691e-01       8.073465e-01   \n",
       "9        8.376578e-01       8.773361e-01       8.760245e-01   \n",
       "10       7.707995e-01       7.262177e-01       7.846485e-01   \n",
       "11       8.388461e-01       8.775514e-01       8.766443e-01   \n",
       "12       7.508355e-01       7.014867e-01       7.627845e-01   \n",
       "13       8.398203e-01       8.775067e-01       8.772574e-01   \n",
       "14       7.313471e-01       6.784592e-01       7.418068e-01   \n",
       "15       8.406307e-01       8.773169e-01       8.778294e-01   \n",
       "16       7.124530e-01       6.569473e-01       7.217193e-01   \n",
       "17       8.413125e-01       8.770417e-01       8.783500e-01   \n",
       "18       6.942137e-01       6.367918e-01       7.025027e-01   \n",
       "19       8.418918e-01       8.767150e-01       8.788182e-01   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0       -2.838771e+23    -1.666233e+23    1.493970e+23               20  \n",
       "1       -2.749682e+17    -1.776262e+18    1.353511e+18               19  \n",
       "2        7.416772e-01     8.431226e-01    5.562247e-02                1  \n",
       "3        6.983258e-01     8.355977e-01    7.230777e-02               10  \n",
       "4        7.326630e-01     8.222963e-01    5.047898e-02               11  \n",
       "5        7.042550e-01     8.385587e-01    7.074721e-02                9  \n",
       "6        7.173267e-01     7.993716e-01    4.770632e-02               12  \n",
       "7        7.072418e-01     8.400011e-01    6.985271e-02                8  \n",
       "8        7.001133e-01     7.765024e-01    4.592148e-02               13  \n",
       "9        7.090029e-01     8.409349e-01    6.932980e-02                7  \n",
       "10       6.824235e-01     7.542727e-01    4.461929e-02               14  \n",
       "11       7.101020e-01     8.415995e-01    6.902303e-02                6  \n",
       "12       6.648460e-01     7.328839e-01    4.357066e-02               15  \n",
       "13       7.107934e-01     8.420913e-01    6.885142e-02                5  \n",
       "14       6.476584e-01     7.123999e-01    4.266177e-02               16  \n",
       "15       7.112129e-01     8.424611e-01    6.876910e-02                4  \n",
       "16       6.309960e-01     6.928268e-01    4.183339e-02               17  \n",
       "17       7.114416e-01     8.427399e-01    6.874816e-02                3  \n",
       "18       6.149217e-01     6.741432e-01    4.105389e-02               18  \n",
       "19       7.115312e-01     8.429484e-01    6.877061e-02                2  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean_fit_time</th>\n      <th>std_fit_time</th>\n      <th>mean_score_time</th>\n      <th>std_score_time</th>\n      <th>param_alpha</th>\n      <th>param_normalize</th>\n      <th>params</th>\n      <th>split0_test_score</th>\n      <th>split1_test_score</th>\n      <th>split2_test_score</th>\n      <th>split3_test_score</th>\n      <th>split4_test_score</th>\n      <th>mean_test_score</th>\n      <th>std_test_score</th>\n      <th>rank_test_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.648920</td>\n      <td>0.259759</td>\n      <td>0.023654</td>\n      <td>0.006074</td>\n      <td>0</td>\n      <td>True</td>\n      <td>{'alpha': 0, 'normalize': True}</td>\n      <td>-1.058609e+23</td>\n      <td>-3.968341e+23</td>\n      <td>-2.878326e+22</td>\n      <td>-1.776099e+22</td>\n      <td>-2.838771e+23</td>\n      <td>-1.666233e+23</td>\n      <td>1.493970e+23</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.321581</td>\n      <td>0.102144</td>\n      <td>0.013781</td>\n      <td>0.007737</td>\n      <td>0</td>\n      <td>False</td>\n      <td>{'alpha': 0, 'normalize': False}</td>\n      <td>-2.039183e+18</td>\n      <td>-4.238480e+18</td>\n      <td>-1.051341e+18</td>\n      <td>-1.277339e+18</td>\n      <td>-2.749682e+17</td>\n      <td>-1.776262e+18</td>\n      <td>1.353511e+18</td>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.106468</td>\n      <td>0.045240</td>\n      <td>0.027765</td>\n      <td>0.012007</td>\n      <td>1</td>\n      <td>True</td>\n      <td>{'alpha': 1, 'normalize': True}</td>\n      <td>9.065174e-01</td>\n      <td>8.459223e-01</td>\n      <td>8.444678e-01</td>\n      <td>8.770281e-01</td>\n      <td>7.416772e-01</td>\n      <td>8.431226e-01</td>\n      <td>5.562247e-02</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.086091</td>\n      <td>0.021496</td>\n      <td>0.017611</td>\n      <td>0.004860</td>\n      <td>1</td>\n      <td>False</td>\n      <td>{'alpha': 1, 'normalize': False}</td>\n      <td>9.026234e-01</td>\n      <td>8.316129e-01</td>\n      <td>8.685269e-01</td>\n      <td>8.768996e-01</td>\n      <td>6.983258e-01</td>\n      <td>8.355977e-01</td>\n      <td>7.230777e-02</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.098017</td>\n      <td>0.034316</td>\n      <td>0.028329</td>\n      <td>0.011141</td>\n      <td>2</td>\n      <td>True</td>\n      <td>{'alpha': 2, 'normalize': True}</td>\n      <td>8.816736e-01</td>\n      <td>8.301339e-01</td>\n      <td>8.126712e-01</td>\n      <td>8.543397e-01</td>\n      <td>7.326630e-01</td>\n      <td>8.222963e-01</td>\n      <td>5.047898e-02</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.102939</td>\n      <td>0.027446</td>\n      <td>0.024647</td>\n      <td>0.005905</td>\n      <td>2</td>\n      <td>False</td>\n      <td>{'alpha': 2, 'normalize': False}</td>\n      <td>9.042165e-01</td>\n      <td>8.342819e-01</td>\n      <td>8.746565e-01</td>\n      <td>8.753836e-01</td>\n      <td>7.042550e-01</td>\n      <td>8.385587e-01</td>\n      <td>7.074721e-02</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.089519</td>\n      <td>0.024883</td>\n      <td>0.031928</td>\n      <td>0.009502</td>\n      <td>3</td>\n      <td>True</td>\n      <td>{'alpha': 3, 'normalize': True}</td>\n      <td>8.560718e-01</td>\n      <td>8.110771e-01</td>\n      <td>7.816641e-01</td>\n      <td>8.307184e-01</td>\n      <td>7.173267e-01</td>\n      <td>7.993716e-01</td>\n      <td>4.770632e-02</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.085205</td>\n      <td>0.026895</td>\n      <td>0.034763</td>\n      <td>0.011454</td>\n      <td>3</td>\n      <td>False</td>\n      <td>{'alpha': 3, 'normalize': False}</td>\n      <td>9.044784e-01</td>\n      <td>8.361798e-01</td>\n      <td>8.766061e-01</td>\n      <td>8.754993e-01</td>\n      <td>7.072418e-01</td>\n      <td>8.400011e-01</td>\n      <td>6.985271e-02</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.128895</td>\n      <td>0.029316</td>\n      <td>0.029292</td>\n      <td>0.004729</td>\n      <td>4</td>\n      <td>True</td>\n      <td>{'alpha': 4, 'normalize': True}</td>\n      <td>8.311651e-01</td>\n      <td>7.910181e-01</td>\n      <td>7.528691e-01</td>\n      <td>8.073465e-01</td>\n      <td>7.001133e-01</td>\n      <td>7.765024e-01</td>\n      <td>4.592148e-02</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.104173</td>\n      <td>0.015145</td>\n      <td>0.031349</td>\n      <td>0.007418</td>\n      <td>4</td>\n      <td>False</td>\n      <td>{'alpha': 4, 'normalize': False}</td>\n      <td>9.046529e-01</td>\n      <td>8.376578e-01</td>\n      <td>8.773361e-01</td>\n      <td>8.760245e-01</td>\n      <td>7.090029e-01</td>\n      <td>8.409349e-01</td>\n      <td>6.932980e-02</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0.039652</td>\n      <td>0.006686</td>\n      <td>0.011052</td>\n      <td>0.004363</td>\n      <td>5</td>\n      <td>True</td>\n      <td>{'alpha': 5, 'normalize': True}</td>\n      <td>8.072745e-01</td>\n      <td>7.707995e-01</td>\n      <td>7.262177e-01</td>\n      <td>7.846485e-01</td>\n      <td>6.824235e-01</td>\n      <td>7.542727e-01</td>\n      <td>4.461929e-02</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>0.052750</td>\n      <td>0.018004</td>\n      <td>0.016676</td>\n      <td>0.009494</td>\n      <td>5</td>\n      <td>False</td>\n      <td>{'alpha': 5, 'normalize': False}</td>\n      <td>9.048534e-01</td>\n      <td>8.388461e-01</td>\n      <td>8.775514e-01</td>\n      <td>8.766443e-01</td>\n      <td>7.101020e-01</td>\n      <td>8.415995e-01</td>\n      <td>6.902303e-02</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>0.068757</td>\n      <td>0.028621</td>\n      <td>0.021318</td>\n      <td>0.017737</td>\n      <td>6</td>\n      <td>True</td>\n      <td>{'alpha': 6, 'normalize': True}</td>\n      <td>7.844665e-01</td>\n      <td>7.508355e-01</td>\n      <td>7.014867e-01</td>\n      <td>7.627845e-01</td>\n      <td>6.648460e-01</td>\n      <td>7.328839e-01</td>\n      <td>4.357066e-02</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>0.026467</td>\n      <td>0.008877</td>\n      <td>0.008103</td>\n      <td>0.004211</td>\n      <td>6</td>\n      <td>False</td>\n      <td>{'alpha': 6, 'normalize': False}</td>\n      <td>9.050785e-01</td>\n      <td>8.398203e-01</td>\n      <td>8.775067e-01</td>\n      <td>8.772574e-01</td>\n      <td>7.107934e-01</td>\n      <td>8.420913e-01</td>\n      <td>6.885142e-02</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>0.031730</td>\n      <td>0.011564</td>\n      <td>0.006957</td>\n      <td>0.002395</td>\n      <td>7</td>\n      <td>True</td>\n      <td>{'alpha': 7, 'normalize': True}</td>\n      <td>7.627283e-01</td>\n      <td>7.313471e-01</td>\n      <td>6.784592e-01</td>\n      <td>7.418068e-01</td>\n      <td>6.476584e-01</td>\n      <td>7.123999e-01</td>\n      <td>4.266177e-02</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>0.040627</td>\n      <td>0.014419</td>\n      <td>0.008409</td>\n      <td>0.004325</td>\n      <td>7</td>\n      <td>False</td>\n      <td>{'alpha': 7, 'normalize': False}</td>\n      <td>9.053154e-01</td>\n      <td>8.406307e-01</td>\n      <td>8.773169e-01</td>\n      <td>8.778294e-01</td>\n      <td>7.112129e-01</td>\n      <td>8.424611e-01</td>\n      <td>6.876910e-02</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>0.066196</td>\n      <td>0.035307</td>\n      <td>0.017093</td>\n      <td>0.005617</td>\n      <td>8</td>\n      <td>True</td>\n      <td>{'alpha': 8, 'normalize': True}</td>\n      <td>7.420184e-01</td>\n      <td>7.124530e-01</td>\n      <td>6.569473e-01</td>\n      <td>7.217193e-01</td>\n      <td>6.309960e-01</td>\n      <td>6.928268e-01</td>\n      <td>4.183339e-02</td>\n      <td>17</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>0.066799</td>\n      <td>0.014849</td>\n      <td>0.021475</td>\n      <td>0.008398</td>\n      <td>8</td>\n      <td>False</td>\n      <td>{'alpha': 8, 'normalize': False}</td>\n      <td>9.055536e-01</td>\n      <td>8.413125e-01</td>\n      <td>8.770417e-01</td>\n      <td>8.783500e-01</td>\n      <td>7.114416e-01</td>\n      <td>8.427399e-01</td>\n      <td>6.874816e-02</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>0.068988</td>\n      <td>0.023502</td>\n      <td>0.011926</td>\n      <td>0.004087</td>\n      <td>9</td>\n      <td>True</td>\n      <td>{'alpha': 9, 'normalize': True}</td>\n      <td>7.222859e-01</td>\n      <td>6.942137e-01</td>\n      <td>6.367918e-01</td>\n      <td>7.025027e-01</td>\n      <td>6.149217e-01</td>\n      <td>6.741432e-01</td>\n      <td>4.105389e-02</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>0.050481</td>\n      <td>0.025035</td>\n      <td>0.009082</td>\n      <td>0.005231</td>\n      <td>9</td>\n      <td>False</td>\n      <td>{'alpha': 9, 'normalize': False}</td>\n      <td>9.057860e-01</td>\n      <td>8.418918e-01</td>\n      <td>8.767150e-01</td>\n      <td>8.788182e-01</td>\n      <td>7.115312e-01</td>\n      <td>8.429484e-01</td>\n      <td>6.877061e-02</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 960
    }
   ],
   "source": [
    "results = pd.DataFrame(defined_ridge_grid.cv_results_)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 961,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Ridge(alpha=1, normalize=True)\n"
     ]
    }
   ],
   "source": [
    "print(defined_ridge_grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 962,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training set : R2 = 0.893, RMSE = 25494.259\nTesting  set : R2 = 0.864, RMSE = 31152.102\n\n\n"
     ]
    }
   ],
   "source": [
    "get_model_metrics(linear_model.Ridge(alpha=14), concatenated_columns[concatenated_columns.columns.to_list()], sale_column, b1=False, b0=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 963,
   "metadata": {},
   "outputs": [],
   "source": [
    "defined_lasso_grid = modelizing_GridSearchCV(concatenated_columns, sale_column, concatenated_columns.columns.to_list(), {'alpha':np.arange(100, 110, 1).tolist()}, linear_model.Lasso())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 964,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_alpha  \\\n",
       "0       0.242777      0.076780         0.031408        0.009126         100   \n",
       "1       0.229497      0.106562         0.021578        0.005078         101   \n",
       "2       0.196658      0.082409         0.024075        0.008321         102   \n",
       "3       0.163152      0.019847         0.021907        0.009649         103   \n",
       "4       0.147905      0.036595         0.012774        0.007562         104   \n",
       "5       0.157983      0.040164         0.026729        0.006455         105   \n",
       "6       0.171858      0.089418         0.027571        0.010710         106   \n",
       "7       0.121271      0.033464         0.020433        0.010594         107   \n",
       "8       0.207537      0.074107         0.036548        0.021149         108   \n",
       "9       0.220739      0.050974         0.041605        0.010462         109   \n",
       "\n",
       "           params  split0_test_score  split1_test_score  split2_test_score  \\\n",
       "0  {'alpha': 100}           0.916312           0.841638           0.871830   \n",
       "1  {'alpha': 101}           0.916299           0.841776           0.872055   \n",
       "2  {'alpha': 102}           0.916284           0.841913           0.872270   \n",
       "3  {'alpha': 103}           0.916269           0.842048           0.872481   \n",
       "4  {'alpha': 104}           0.916252           0.842176           0.872688   \n",
       "5  {'alpha': 105}           0.916238           0.842299           0.872891   \n",
       "6  {'alpha': 106}           0.916223           0.842420           0.873090   \n",
       "7  {'alpha': 107}           0.916208           0.842539           0.873284   \n",
       "8  {'alpha': 108}           0.916192           0.842652           0.873474   \n",
       "9  {'alpha': 109}           0.916174           0.842762           0.873663   \n",
       "\n",
       "   split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n",
       "0           0.900695           0.718797         0.849854        0.070324   \n",
       "1           0.900671           0.718768         0.849914        0.070341   \n",
       "2           0.900634           0.718742         0.849969        0.070353   \n",
       "3           0.900600           0.718718         0.850023        0.070364   \n",
       "4           0.900566           0.718690         0.850074        0.070377   \n",
       "5           0.900531           0.718653         0.850122        0.070393   \n",
       "6           0.900495           0.718615         0.850168        0.070410   \n",
       "7           0.900458           0.718577         0.850213        0.070426   \n",
       "8           0.900419           0.718538         0.850255        0.070442   \n",
       "9           0.900380           0.718499         0.850296        0.070458   \n",
       "\n",
       "   rank_test_score  \n",
       "0               10  \n",
       "1                9  \n",
       "2                8  \n",
       "3                7  \n",
       "4                6  \n",
       "5                5  \n",
       "6                4  \n",
       "7                3  \n",
       "8                2  \n",
       "9                1  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean_fit_time</th>\n      <th>std_fit_time</th>\n      <th>mean_score_time</th>\n      <th>std_score_time</th>\n      <th>param_alpha</th>\n      <th>params</th>\n      <th>split0_test_score</th>\n      <th>split1_test_score</th>\n      <th>split2_test_score</th>\n      <th>split3_test_score</th>\n      <th>split4_test_score</th>\n      <th>mean_test_score</th>\n      <th>std_test_score</th>\n      <th>rank_test_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.242777</td>\n      <td>0.076780</td>\n      <td>0.031408</td>\n      <td>0.009126</td>\n      <td>100</td>\n      <td>{'alpha': 100}</td>\n      <td>0.916312</td>\n      <td>0.841638</td>\n      <td>0.871830</td>\n      <td>0.900695</td>\n      <td>0.718797</td>\n      <td>0.849854</td>\n      <td>0.070324</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.229497</td>\n      <td>0.106562</td>\n      <td>0.021578</td>\n      <td>0.005078</td>\n      <td>101</td>\n      <td>{'alpha': 101}</td>\n      <td>0.916299</td>\n      <td>0.841776</td>\n      <td>0.872055</td>\n      <td>0.900671</td>\n      <td>0.718768</td>\n      <td>0.849914</td>\n      <td>0.070341</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.196658</td>\n      <td>0.082409</td>\n      <td>0.024075</td>\n      <td>0.008321</td>\n      <td>102</td>\n      <td>{'alpha': 102}</td>\n      <td>0.916284</td>\n      <td>0.841913</td>\n      <td>0.872270</td>\n      <td>0.900634</td>\n      <td>0.718742</td>\n      <td>0.849969</td>\n      <td>0.070353</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.163152</td>\n      <td>0.019847</td>\n      <td>0.021907</td>\n      <td>0.009649</td>\n      <td>103</td>\n      <td>{'alpha': 103}</td>\n      <td>0.916269</td>\n      <td>0.842048</td>\n      <td>0.872481</td>\n      <td>0.900600</td>\n      <td>0.718718</td>\n      <td>0.850023</td>\n      <td>0.070364</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.147905</td>\n      <td>0.036595</td>\n      <td>0.012774</td>\n      <td>0.007562</td>\n      <td>104</td>\n      <td>{'alpha': 104}</td>\n      <td>0.916252</td>\n      <td>0.842176</td>\n      <td>0.872688</td>\n      <td>0.900566</td>\n      <td>0.718690</td>\n      <td>0.850074</td>\n      <td>0.070377</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.157983</td>\n      <td>0.040164</td>\n      <td>0.026729</td>\n      <td>0.006455</td>\n      <td>105</td>\n      <td>{'alpha': 105}</td>\n      <td>0.916238</td>\n      <td>0.842299</td>\n      <td>0.872891</td>\n      <td>0.900531</td>\n      <td>0.718653</td>\n      <td>0.850122</td>\n      <td>0.070393</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.171858</td>\n      <td>0.089418</td>\n      <td>0.027571</td>\n      <td>0.010710</td>\n      <td>106</td>\n      <td>{'alpha': 106}</td>\n      <td>0.916223</td>\n      <td>0.842420</td>\n      <td>0.873090</td>\n      <td>0.900495</td>\n      <td>0.718615</td>\n      <td>0.850168</td>\n      <td>0.070410</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.121271</td>\n      <td>0.033464</td>\n      <td>0.020433</td>\n      <td>0.010594</td>\n      <td>107</td>\n      <td>{'alpha': 107}</td>\n      <td>0.916208</td>\n      <td>0.842539</td>\n      <td>0.873284</td>\n      <td>0.900458</td>\n      <td>0.718577</td>\n      <td>0.850213</td>\n      <td>0.070426</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.207537</td>\n      <td>0.074107</td>\n      <td>0.036548</td>\n      <td>0.021149</td>\n      <td>108</td>\n      <td>{'alpha': 108}</td>\n      <td>0.916192</td>\n      <td>0.842652</td>\n      <td>0.873474</td>\n      <td>0.900419</td>\n      <td>0.718538</td>\n      <td>0.850255</td>\n      <td>0.070442</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.220739</td>\n      <td>0.050974</td>\n      <td>0.041605</td>\n      <td>0.010462</td>\n      <td>109</td>\n      <td>{'alpha': 109}</td>\n      <td>0.916174</td>\n      <td>0.842762</td>\n      <td>0.873663</td>\n      <td>0.900380</td>\n      <td>0.718499</td>\n      <td>0.850296</td>\n      <td>0.070458</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 964
    }
   ],
   "source": [
    "results_lasso = pd.DataFrame(defined_lasso_grid.cv_results_)\n",
    "results_lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 965,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Lasso(alpha=109)\n"
     ]
    }
   ],
   "source": [
    "print(defined_lasso_grid.best_estimator_)"
   ]
  },
  {
   "source": [
    "## Utilisation du RandomizedSearchCV (Cross-Validation)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 966,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "\n",
    "def modelizing_RandomizedSearchCV(database, target_value, evaluated_values, defined_parameters, model_name, n_iter=10, cv=5, random_state=None):\n",
    "    y = target_value\n",
    "    x = database[evaluated_values]\n",
    "    parameters = defined_parameters\n",
    "    model = model_name\n",
    "    regr = RandomizedSearchCV(model, parameters, n_iter=n_iter, cv=cv, random_state=random_state)\n",
    "    regr.fit(x, y)\n",
    "    return regr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 868,
   "metadata": {},
   "outputs": [],
   "source": [
    "defined_ridge_randomized = modelizing_RandomizedSearchCV(concatenated_columns, sale_column, concatenated_columns.columns.to_list(), {'alpha':uniform(loc=0, scale=10), 'normalize':[True, False]}, linear_model.Ridge(), random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 869,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_alpha  \\\n",
       "0       0.109969      0.030597         0.026958        0.010159     4.17022   \n",
       "1       0.079899      0.023330         0.026020        0.003417    9.325574   \n",
       "2       0.106794      0.027723         0.027834        0.007307    3.023326   \n",
       "3       0.091676      0.042085         0.025454        0.004819     2.36089   \n",
       "4       0.091112      0.014731         0.021868        0.006507    1.862602   \n",
       "5       0.064055      0.023363         0.013772        0.007396     6.69746   \n",
       "6       0.108450      0.023778         0.030396        0.012000    5.388167   \n",
       "7       0.052694      0.007324         0.022803        0.007898    3.132735   \n",
       "8       0.067374      0.031060         0.018613        0.005325    2.044522   \n",
       "9       0.041040      0.027060         0.010316        0.004628    2.295772   \n",
       "\n",
       "  param_normalize                                             params  \\\n",
       "0            True     {'alpha': 4.17022004702574, 'normalize': True}   \n",
       "1           False   {'alpha': 9.325573593386588, 'normalize': False}   \n",
       "2           False  {'alpha': 3.0233257263183977, 'normalize': False}   \n",
       "3           False  {'alpha': 2.3608897695197606, 'normalize': False}   \n",
       "4           False   {'alpha': 1.862602113776709, 'normalize': False}   \n",
       "5           False     {'alpha': 6.6974603680348, 'normalize': False}   \n",
       "6            True   {'alpha': 5.3881673400335695, 'normalize': True}   \n",
       "7            True    {'alpha': 3.132735169322751, 'normalize': True}   \n",
       "8            True   {'alpha': 2.0445224973151745, 'normalize': True}   \n",
       "9            True   {'alpha': 2.2957721372982554, 'normalize': True}   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0           0.827023           0.787573           0.748187           0.803429   \n",
       "1           0.905860           0.842062           0.876601           0.878960   \n",
       "2           0.904483           0.836218           0.876633           0.875509   \n",
       "3           0.904344           0.835028           0.875590           0.875338   \n",
       "4           0.904144           0.833975           0.874196           0.875443   \n",
       "5           0.905243           0.840400           0.877385           0.877662   \n",
       "6           0.798292           0.763005           0.716402           0.776058   \n",
       "7           0.852714           0.808447           0.777712           0.827588   \n",
       "8           0.880530           0.829328           0.811250           0.853294   \n",
       "9           0.874072           0.824685           0.803289           0.847373   \n",
       "\n",
       "   split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0           0.697114         0.772665        0.045674                9  \n",
       "1           0.711537         0.843004        0.068785                1  \n",
       "2           0.707294         0.840027        0.069837                3  \n",
       "3           0.705537         0.839167        0.070367                4  \n",
       "4           0.703684         0.838288        0.070914                5  \n",
       "5           0.711109         0.842360        0.068786                2  \n",
       "6           0.675568         0.745865        0.044190               10  \n",
       "7           0.715106         0.796313        0.047428                8  \n",
       "8           0.732059         0.821292        0.050322                6  \n",
       "9           0.728475         0.815579        0.049504                7  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean_fit_time</th>\n      <th>std_fit_time</th>\n      <th>mean_score_time</th>\n      <th>std_score_time</th>\n      <th>param_alpha</th>\n      <th>param_normalize</th>\n      <th>params</th>\n      <th>split0_test_score</th>\n      <th>split1_test_score</th>\n      <th>split2_test_score</th>\n      <th>split3_test_score</th>\n      <th>split4_test_score</th>\n      <th>mean_test_score</th>\n      <th>std_test_score</th>\n      <th>rank_test_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.109969</td>\n      <td>0.030597</td>\n      <td>0.026958</td>\n      <td>0.010159</td>\n      <td>4.17022</td>\n      <td>True</td>\n      <td>{'alpha': 4.17022004702574, 'normalize': True}</td>\n      <td>0.827023</td>\n      <td>0.787573</td>\n      <td>0.748187</td>\n      <td>0.803429</td>\n      <td>0.697114</td>\n      <td>0.772665</td>\n      <td>0.045674</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.079899</td>\n      <td>0.023330</td>\n      <td>0.026020</td>\n      <td>0.003417</td>\n      <td>9.325574</td>\n      <td>False</td>\n      <td>{'alpha': 9.325573593386588, 'normalize': False}</td>\n      <td>0.905860</td>\n      <td>0.842062</td>\n      <td>0.876601</td>\n      <td>0.878960</td>\n      <td>0.711537</td>\n      <td>0.843004</td>\n      <td>0.068785</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.106794</td>\n      <td>0.027723</td>\n      <td>0.027834</td>\n      <td>0.007307</td>\n      <td>3.023326</td>\n      <td>False</td>\n      <td>{'alpha': 3.0233257263183977, 'normalize': False}</td>\n      <td>0.904483</td>\n      <td>0.836218</td>\n      <td>0.876633</td>\n      <td>0.875509</td>\n      <td>0.707294</td>\n      <td>0.840027</td>\n      <td>0.069837</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.091676</td>\n      <td>0.042085</td>\n      <td>0.025454</td>\n      <td>0.004819</td>\n      <td>2.36089</td>\n      <td>False</td>\n      <td>{'alpha': 2.3608897695197606, 'normalize': False}</td>\n      <td>0.904344</td>\n      <td>0.835028</td>\n      <td>0.875590</td>\n      <td>0.875338</td>\n      <td>0.705537</td>\n      <td>0.839167</td>\n      <td>0.070367</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.091112</td>\n      <td>0.014731</td>\n      <td>0.021868</td>\n      <td>0.006507</td>\n      <td>1.862602</td>\n      <td>False</td>\n      <td>{'alpha': 1.862602113776709, 'normalize': False}</td>\n      <td>0.904144</td>\n      <td>0.833975</td>\n      <td>0.874196</td>\n      <td>0.875443</td>\n      <td>0.703684</td>\n      <td>0.838288</td>\n      <td>0.070914</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.064055</td>\n      <td>0.023363</td>\n      <td>0.013772</td>\n      <td>0.007396</td>\n      <td>6.69746</td>\n      <td>False</td>\n      <td>{'alpha': 6.6974603680348, 'normalize': False}</td>\n      <td>0.905243</td>\n      <td>0.840400</td>\n      <td>0.877385</td>\n      <td>0.877662</td>\n      <td>0.711109</td>\n      <td>0.842360</td>\n      <td>0.068786</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.108450</td>\n      <td>0.023778</td>\n      <td>0.030396</td>\n      <td>0.012000</td>\n      <td>5.388167</td>\n      <td>True</td>\n      <td>{'alpha': 5.3881673400335695, 'normalize': True}</td>\n      <td>0.798292</td>\n      <td>0.763005</td>\n      <td>0.716402</td>\n      <td>0.776058</td>\n      <td>0.675568</td>\n      <td>0.745865</td>\n      <td>0.044190</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.052694</td>\n      <td>0.007324</td>\n      <td>0.022803</td>\n      <td>0.007898</td>\n      <td>3.132735</td>\n      <td>True</td>\n      <td>{'alpha': 3.132735169322751, 'normalize': True}</td>\n      <td>0.852714</td>\n      <td>0.808447</td>\n      <td>0.777712</td>\n      <td>0.827588</td>\n      <td>0.715106</td>\n      <td>0.796313</td>\n      <td>0.047428</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.067374</td>\n      <td>0.031060</td>\n      <td>0.018613</td>\n      <td>0.005325</td>\n      <td>2.044522</td>\n      <td>True</td>\n      <td>{'alpha': 2.0445224973151745, 'normalize': True}</td>\n      <td>0.880530</td>\n      <td>0.829328</td>\n      <td>0.811250</td>\n      <td>0.853294</td>\n      <td>0.732059</td>\n      <td>0.821292</td>\n      <td>0.050322</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.041040</td>\n      <td>0.027060</td>\n      <td>0.010316</td>\n      <td>0.004628</td>\n      <td>2.295772</td>\n      <td>True</td>\n      <td>{'alpha': 2.2957721372982554, 'normalize': True}</td>\n      <td>0.874072</td>\n      <td>0.824685</td>\n      <td>0.803289</td>\n      <td>0.847373</td>\n      <td>0.728475</td>\n      <td>0.815579</td>\n      <td>0.049504</td>\n      <td>7</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 869
    }
   ],
   "source": [
    "results_randomized_ridge = pd.DataFrame(defined_ridge_randomized.cv_results_)\n",
    "results_randomized_ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 870,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Ridge(alpha=9.325573593386588)"
      ]
     },
     "metadata": {},
     "execution_count": 870
    }
   ],
   "source": [
    "defined_ridge_randomized.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 871,
   "metadata": {},
   "outputs": [],
   "source": [
    "defined_lasso_randomized = modelizing_RandomizedSearchCV(concatenated_columns, sale_column, concatenated_columns.columns.to_list(), {'alpha':uniform(loc=100, scale=500), 'normalize':[True, False]}, linear_model.Lasso(), random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 872,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_alpha  \\\n",
       "0       0.083967      0.025526         0.032810        0.012520  308.511002   \n",
       "1       0.120615      0.057130         0.016660        0.002878   566.27868   \n",
       "2       0.159731      0.031812         0.023827        0.005677  251.166286   \n",
       "3       0.164601      0.031257         0.038939        0.021005  218.044488   \n",
       "4       0.193052      0.058510         0.036297        0.013106  193.130106   \n",
       "5       0.121985      0.031713         0.025942        0.006372  434.873018   \n",
       "6       0.085960      0.011085         0.014853        0.005916  369.408367   \n",
       "7       0.088427      0.006242         0.016325        0.002697  256.636758   \n",
       "8       0.081916      0.020268         0.026464        0.013048  202.226125   \n",
       "9       0.028917      0.000953         0.011124        0.004782  214.788607   \n",
       "\n",
       "  param_normalize                                             params  \\\n",
       "0            True     {'alpha': 308.511002351287, 'normalize': True}   \n",
       "1           False   {'alpha': 566.2786796693294, 'normalize': False}   \n",
       "2           False  {'alpha': 251.16628631591988, 'normalize': False}   \n",
       "3           False  {'alpha': 218.04448847598803, 'normalize': False}   \n",
       "4           False  {'alpha': 193.13010568883544, 'normalize': False}   \n",
       "5           False     {'alpha': 434.87301840174, 'normalize': False}   \n",
       "6            True   {'alpha': 369.40836700167847, 'normalize': True}   \n",
       "7            True   {'alpha': 256.63675846613756, 'normalize': True}   \n",
       "8            True   {'alpha': 202.22612486575872, 'normalize': True}   \n",
       "9            True   {'alpha': 214.78860686491277, 'normalize': True}   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0           0.813074           0.774196           0.726408           0.785717   \n",
       "1           0.895576           0.842323           0.853636           0.873230   \n",
       "2           0.910051           0.848243           0.877409           0.888491   \n",
       "3           0.911134           0.847996           0.880550           0.892117   \n",
       "4           0.912591           0.847539           0.881210           0.894592   \n",
       "5           0.902293           0.845172           0.861799           0.878781   \n",
       "6           0.792354           0.755822           0.699306           0.763520   \n",
       "7           0.833117           0.793281           0.753176           0.808956   \n",
       "8           0.853752           0.811849           0.786555           0.830492   \n",
       "9           0.848938           0.807878           0.779365           0.825683   \n",
       "\n",
       "   split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0           0.686002         0.757079        0.045257                9  \n",
       "1           0.687609         0.830475        0.073693                5  \n",
       "2           0.711610         0.847161        0.070645                3  \n",
       "3           0.712606         0.848881        0.071161                2  \n",
       "4           0.713225         0.849831        0.071545                1  \n",
       "5           0.699470         0.837503        0.071560                4  \n",
       "6           0.678872         0.737975        0.042229               10  \n",
       "7           0.690708         0.775848        0.049885                8  \n",
       "8           0.693787         0.795287        0.055336                6  \n",
       "9           0.691951         0.790763        0.054388                7  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean_fit_time</th>\n      <th>std_fit_time</th>\n      <th>mean_score_time</th>\n      <th>std_score_time</th>\n      <th>param_alpha</th>\n      <th>param_normalize</th>\n      <th>params</th>\n      <th>split0_test_score</th>\n      <th>split1_test_score</th>\n      <th>split2_test_score</th>\n      <th>split3_test_score</th>\n      <th>split4_test_score</th>\n      <th>mean_test_score</th>\n      <th>std_test_score</th>\n      <th>rank_test_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.083967</td>\n      <td>0.025526</td>\n      <td>0.032810</td>\n      <td>0.012520</td>\n      <td>308.511002</td>\n      <td>True</td>\n      <td>{'alpha': 308.511002351287, 'normalize': True}</td>\n      <td>0.813074</td>\n      <td>0.774196</td>\n      <td>0.726408</td>\n      <td>0.785717</td>\n      <td>0.686002</td>\n      <td>0.757079</td>\n      <td>0.045257</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.120615</td>\n      <td>0.057130</td>\n      <td>0.016660</td>\n      <td>0.002878</td>\n      <td>566.27868</td>\n      <td>False</td>\n      <td>{'alpha': 566.2786796693294, 'normalize': False}</td>\n      <td>0.895576</td>\n      <td>0.842323</td>\n      <td>0.853636</td>\n      <td>0.873230</td>\n      <td>0.687609</td>\n      <td>0.830475</td>\n      <td>0.073693</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.159731</td>\n      <td>0.031812</td>\n      <td>0.023827</td>\n      <td>0.005677</td>\n      <td>251.166286</td>\n      <td>False</td>\n      <td>{'alpha': 251.16628631591988, 'normalize': False}</td>\n      <td>0.910051</td>\n      <td>0.848243</td>\n      <td>0.877409</td>\n      <td>0.888491</td>\n      <td>0.711610</td>\n      <td>0.847161</td>\n      <td>0.070645</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.164601</td>\n      <td>0.031257</td>\n      <td>0.038939</td>\n      <td>0.021005</td>\n      <td>218.044488</td>\n      <td>False</td>\n      <td>{'alpha': 218.04448847598803, 'normalize': False}</td>\n      <td>0.911134</td>\n      <td>0.847996</td>\n      <td>0.880550</td>\n      <td>0.892117</td>\n      <td>0.712606</td>\n      <td>0.848881</td>\n      <td>0.071161</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.193052</td>\n      <td>0.058510</td>\n      <td>0.036297</td>\n      <td>0.013106</td>\n      <td>193.130106</td>\n      <td>False</td>\n      <td>{'alpha': 193.13010568883544, 'normalize': False}</td>\n      <td>0.912591</td>\n      <td>0.847539</td>\n      <td>0.881210</td>\n      <td>0.894592</td>\n      <td>0.713225</td>\n      <td>0.849831</td>\n      <td>0.071545</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.121985</td>\n      <td>0.031713</td>\n      <td>0.025942</td>\n      <td>0.006372</td>\n      <td>434.873018</td>\n      <td>False</td>\n      <td>{'alpha': 434.87301840174, 'normalize': False}</td>\n      <td>0.902293</td>\n      <td>0.845172</td>\n      <td>0.861799</td>\n      <td>0.878781</td>\n      <td>0.699470</td>\n      <td>0.837503</td>\n      <td>0.071560</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.085960</td>\n      <td>0.011085</td>\n      <td>0.014853</td>\n      <td>0.005916</td>\n      <td>369.408367</td>\n      <td>True</td>\n      <td>{'alpha': 369.40836700167847, 'normalize': True}</td>\n      <td>0.792354</td>\n      <td>0.755822</td>\n      <td>0.699306</td>\n      <td>0.763520</td>\n      <td>0.678872</td>\n      <td>0.737975</td>\n      <td>0.042229</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.088427</td>\n      <td>0.006242</td>\n      <td>0.016325</td>\n      <td>0.002697</td>\n      <td>256.636758</td>\n      <td>True</td>\n      <td>{'alpha': 256.63675846613756, 'normalize': True}</td>\n      <td>0.833117</td>\n      <td>0.793281</td>\n      <td>0.753176</td>\n      <td>0.808956</td>\n      <td>0.690708</td>\n      <td>0.775848</td>\n      <td>0.049885</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.081916</td>\n      <td>0.020268</td>\n      <td>0.026464</td>\n      <td>0.013048</td>\n      <td>202.226125</td>\n      <td>True</td>\n      <td>{'alpha': 202.22612486575872, 'normalize': True}</td>\n      <td>0.853752</td>\n      <td>0.811849</td>\n      <td>0.786555</td>\n      <td>0.830492</td>\n      <td>0.693787</td>\n      <td>0.795287</td>\n      <td>0.055336</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.028917</td>\n      <td>0.000953</td>\n      <td>0.011124</td>\n      <td>0.004782</td>\n      <td>214.788607</td>\n      <td>True</td>\n      <td>{'alpha': 214.78860686491277, 'normalize': True}</td>\n      <td>0.848938</td>\n      <td>0.807878</td>\n      <td>0.779365</td>\n      <td>0.825683</td>\n      <td>0.691951</td>\n      <td>0.790763</td>\n      <td>0.054388</td>\n      <td>7</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 872
    }
   ],
   "source": [
    "results_randomized_lasso = pd.DataFrame(defined_lasso_randomized.cv_results_)\n",
    "results_randomized_lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 873,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Lasso(alpha=193.13010568883544)"
      ]
     },
     "metadata": {},
     "execution_count": 873
    }
   ],
   "source": [
    "defined_lasso_randomized.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}